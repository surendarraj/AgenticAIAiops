{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dMeesFY_s2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e876cb3-4bf9-41cd-9ddf-e18be6719d8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.7/143.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.3/515.3 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#!pip install -U langgraph langchain  openai huggingface_hub --quiet\n",
        "#!pip install -U langchain-openai --quiet\n",
        "#!pip install -U langchain-community --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "openai.api_key = \"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\""
      ],
      "metadata": {
        "id": "3uDC681S_zmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "def generate_metrics():\n",
        "    df = pd.DataFrame({\n",
        "        \"cpu\": np.random.normal(50, 10, 100),\n",
        "        \"memory\": np.random.normal(60, 15, 100),\n",
        "        \"disk_io\": np.random.normal(100, 25, 100),\n",
        "    })\n",
        "    df.iloc[95:100] += np.random.uniform(100, 200)\n",
        "    return df\n",
        "\n",
        "def detect_anomalies(df):\n",
        "    model = IsolationForest(contamination=0.05, random_state=42)\n",
        "    model.fit(df)\n",
        "    df[\"anomaly\"] = model.predict(df)\n",
        "    return df[df[\"anomaly\"] == -1]\n"
      ],
      "metadata": {
        "id": "_fgfcu5n_6SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, TypedDict, Set\n",
        "from langgraph.graph import StateGraph, END\n",
        "import hashlib\n",
        "\n",
        "class AIOpsState(TypedDict):\n",
        "    chat_history: List[dict]\n",
        "    anomalies: str\n",
        "    seen_anomalies: Set[str]\n"
      ],
      "metadata": {
        "id": "MfkVu_NjppdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def aiops_langchain_agent(state: AIOpsState) -> AIOpsState:\n",
        "    from langchain.chains import LLMChain\n",
        "    from langchain.prompts import PromptTemplate\n",
        "\n",
        "    history = state[\"chat_history\"]\n",
        "    prompt = PromptTemplate.from_template(\n",
        "        \"\"\"Detected anomalies in system metrics:\\n\\n{anomalies}\n",
        "Explain possible causes, system impact, and recommended actions.\"\"\"\n",
        "    )\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "    result = chain.run(anomalies=state[\"anomalies\"])\n",
        "    history.append({\"role\": \"user\", \"content\": prompt.format(anomalies=state[\"anomalies\"])})\n",
        "    history.append({\"role\": \"assistant\", \"content\": result})\n",
        "\n",
        "    return {\n",
        "        \"chat_history\": history,\n",
        "        \"anomalies\": state[\"anomalies\"],\n",
        "        \"seen_anomalies\": state[\"seen_anomalies\"]\n",
        "    }\n"
      ],
      "metadata": {
        "id": "pC_AS400wVkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "\n",
        "def deduplicate_event(state: AIOpsState) -> AIOpsState:\n",
        "    history = state[\"chat_history\"]\n",
        "    hash_id = hashlib.md5(state[\"anomalies\"].encode()).hexdigest()\n",
        "\n",
        "    if hash_id in state[\"seen_anomalies\"]:\n",
        "        history.append({\"role\": \"user\", \"content\": \"Duplicate anomaly detected. Skipping.\"})\n",
        "        history.append({\"role\": \"assistant\", \"content\": \"Anomaly already processed earlier.\"})\n",
        "    else:\n",
        "        state[\"seen_anomalies\"].add(hash_id)\n",
        "\n",
        "    return {\n",
        "        \"chat_history\": history,\n",
        "        \"anomalies\": state[\"anomalies\"],\n",
        "        \"seen_anomalies\": state[\"seen_anomalies\"]\n",
        "    }\n"
      ],
      "metadata": {
        "id": "sXej9mVWuF_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.3, openai_api_key=openai.api_key)\n",
        "def aiops_agent(state: AIOpsState) -> AIOpsState:\n",
        "    history = state.get(\"chat_history\", [])\n",
        "\n",
        "    # Append new prompt with current anomaly\n",
        "    prompt = {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"Detected anomalies in system metrics:\\n\\n{state['anomalies']}\\n\n",
        "Explain the possible causes, impacts, and fixes.\"\"\"\n",
        "    }\n",
        "    history.append(prompt)\n",
        "\n",
        "    # Call ChatGPT\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=history\n",
        "    )\n",
        "    reply = response.choices[0].message.content.strip()\n",
        "\n",
        "    # Save model response\n",
        "    history.append({\"role\": \"assistant\", \"content\": reply})\n",
        "\n",
        "    return {\"chat_history\": history, \"anomalies\": state[\"anomalies\"]}\n"
      ],
      "metadata": {
        "id": "UfU_gE1Gpu1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52d3a3c7-0011-4b0f-cd87-ca8a4e39c2f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-11-1066192067.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model=\"gpt-4\", temperature=0.3, openai_api_key=openai.api_key)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "builder = StateGraph(state_schema=AIOpsState)\n",
        "builder.add_node(\"deduplicate_event\", deduplicate_event)\n",
        "builder.add_node(\"aiops_langchain_agent\", aiops_langchain_agent)\n",
        "\n",
        "builder.set_entry_point(\"deduplicate_event\")\n",
        "builder.add_edge(\"deduplicate_event\", \"aiops_langchain_agent\")\n",
        "builder.add_edge(\"aiops_langchain_agent\", END)\n",
        "\n",
        "graph = builder.compile()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Cl3DUD1E_8PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "def generate_anomalies():\n",
        "    df = pd.DataFrame({\n",
        "        \"cpu\": np.random.normal(50, 10, 100),\n",
        "        \"memory\": np.random.normal(60, 15, 100),\n",
        "        \"disk_io\": np.random.normal(100, 25, 100),\n",
        "    })\n",
        "    df.iloc[95:100] += np.random.uniform(100, 200)\n",
        "    model = IsolationForest(contamination=0.05, random_state=42)\n",
        "    model.fit(df)\n",
        "    df[\"anomaly\"] = model.predict(df)\n",
        "    return df[df[\"anomaly\"] == -1].to_string(index=False)\n"
      ],
      "metadata": {
        "id": "oluO4jrRAAGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Persistent memory state\n",
        "state = {\n",
        "    \"chat_history\": [],\n",
        "    \"seen_anomalies\": set()\n",
        "}\n",
        "\n",
        "# Simulate 2 anomaly events (same data to test deduplication)\n",
        "for i in range(2):\n",
        "    print(f\"\\n Run {i+1}\")\n",
        "    anomaly_str = generate_anomalies()\n",
        "    input_state = {\n",
        "        \"chat_history\": state[\"chat_history\"],\n",
        "        \"anomalies\": anomaly_str,\n",
        "        \"seen_anomalies\": state[\"seen_anomalies\"]\n",
        "    }\n",
        "    state = graph.invoke(input_state)\n",
        "\n",
        "    for msg in state[\"chat_history\"][-2:]:\n",
        "        print(f\"[{msg['role'].upper()}]: {msg['content']}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt_NiYpUwki2",
        "outputId": "b34f8325-918b-437d-8344-981cc9c9de5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Run 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-9-3375322124.py:10: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=prompt)\n",
            "/tmp/ipython-input-9-3375322124.py:12: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = chain.run(anomalies=state[\"anomalies\"])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[USER]: Detected anomalies in system metrics:\n",
            "\n",
            "       cpu     memory    disk_io  anomaly\n",
            "240.523115 253.831366 273.516742       -1\n",
            "249.129242 266.002923 295.341864       -1\n",
            "244.896667 260.474992 241.647476       -1\n",
            "255.505014 265.809492 262.202908       -1\n",
            "249.727892 252.668653 245.781577       -1\n",
            "Explain possible causes, system impact, and recommended actions.\n",
            "\n",
            "[ASSISTANT]: Possible Causes:\n",
            "1. High CPU usage: This could be due to some processes or applications consuming excessive CPU resources. \n",
            "2. High Memory usage: This could be due to memory leaks in applications or too many applications running simultaneously.\n",
            "3. High Disk IO: This could be due to excessive read/write operations on the disk, possibly due to some heavy applications or processes.\n",
            "\n",
            "System Impact:\n",
            "1. High CPU usage can slow down the system and cause applications to respond slowly.\n",
            "2. High Memory usage can cause the system to slow down, freeze, or even crash if it runs out of memory.\n",
            "3. High Disk IO can cause the system to slow down and degrade the lifespan of the hard disk.\n",
            "\n",
            "Recommended Actions:\n",
            "1. High CPU usage: Identify the processes or applications that are consuming high CPU and optimize or limit their usage. If necessary, consider upgrading the CPU.\n",
            "2. High Memory usage: Identify the applications causing memory leaks and fix them. If necessary, consider adding more memory to the system.\n",
            "3. High Disk IO: Identify the processes causing high disk IO and optimize them. Consider using a faster disk or SSD if the disk IO is consistently high.\n",
            "\n",
            "\n",
            " Run 2\n",
            "[USER]: Detected anomalies in system metrics:\n",
            "\n",
            "       cpu     memory    disk_io  anomaly\n",
            "201.660397 210.734409 290.883586       -1\n",
            "199.455262 207.001088 232.371224       -1\n",
            "228.289159 210.560633 218.448125       -1\n",
            "194.223163 178.411210 236.481189       -1\n",
            "194.834252 182.423399 265.714304       -1\n",
            "Explain possible causes, system impact, and recommended actions.\n",
            "\n",
            "[ASSISTANT]: Possible Causes:\n",
            "1. High CPU usage: This could be due to a process or application consuming more CPU resources than expected. It could also be due to a malware attack.\n",
            "2. High Memory usage: This could be due to a memory leak in an application or a process consuming more memory than expected.\n",
            "3. High Disk IO: This could be due to excessive read/write operations on the disk. It could be due to a process or application consuming more disk resources than expected.\n",
            "\n",
            "System Impact:\n",
            "1. High CPU usage can slow down the system and make it unresponsive.\n",
            "2. High Memory usage can lead to system crashes or slow performance due to swapping.\n",
            "3. High Disk IO can slow down the system and cause disk wear.\n",
            "\n",
            "Recommended Actions:\n",
            "1. Identify the process or application causing high CPU usage and optimize it. If it's a malware, use an antivirus to remove it.\n",
            "2. Identify the process or application causing high memory usage and fix the memory leak or optimize it.\n",
            "3. Identify the process or application causing high Disk IO and optimize it. Consider using SSDs for high IO operations.\n",
            "4. Monitor system metrics regularly to detect anomalies early.\n",
            "5. Consider upgrading the system hardware if it's consistently under high load.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}