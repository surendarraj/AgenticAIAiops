{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8dMeesFY_s2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97d0d353-3701-47a5-a110-40d1e5867959"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m765.0/765.0 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U langgraph langchain  openai huggingface_hub --quiet\n",
        "!pip install -U langchain-openai --quiet\n",
        "!pip install -U langchain-community --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "openai.api_key =userdata.get('OPEN_API_KEY')"
      ],
      "metadata": {
        "id": "3uDC681S_zmh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "def generate_metrics():\n",
        "    df = pd.DataFrame({\n",
        "        \"cpu\": np.random.normal(50, 10, 100),\n",
        "        \"memory\": np.random.normal(60, 15, 100),\n",
        "        \"disk_io\": np.random.normal(100, 25, 100),\n",
        "    })\n",
        "    df.iloc[95:100] += np.random.uniform(100, 200)\n",
        "    return df\n",
        "\n",
        "def detect_anomalies(df):\n",
        "    model = IsolationForest(contamination=0.05, random_state=42)\n",
        "    model.fit(df)\n",
        "    df[\"anomaly\"] = model.predict(df)\n",
        "    return df[df[\"anomaly\"] == -1]\n"
      ],
      "metadata": {
        "id": "_fgfcu5n_6SE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, TypedDict, Set\n",
        "from langgraph.graph import StateGraph, END\n",
        "import hashlib\n",
        "\n",
        "class AIOpsState(TypedDict):\n",
        "    chat_history: List[dict]\n",
        "    anomalies: str\n",
        "    seen_anomalies: Set[str]\n"
      ],
      "metadata": {
        "id": "MfkVu_NjppdN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def aiops_langchain_agent(state: AIOpsState) -> AIOpsState:\n",
        "    from langchain.chains import LLMChain\n",
        "    from langchain.prompts import PromptTemplate\n",
        "\n",
        "    history = state[\"chat_history\"]\n",
        "    prompt = PromptTemplate.from_template(\n",
        "        \"\"\"Detected anomalies in system metrics:\\n\\n{anomalies}\n",
        "Explain possible causes, system impact, and recommended actions.\"\"\"\n",
        "    )\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "    result = chain.run(anomalies=state[\"anomalies\"])\n",
        "    history.append({\"role\": \"user\", \"content\": prompt.format(anomalies=state[\"anomalies\"])})\n",
        "    history.append({\"role\": \"assistant\", \"content\": result})\n",
        "\n",
        "    return {\n",
        "        \"chat_history\": history,\n",
        "        \"anomalies\": state[\"anomalies\"],\n",
        "        \"seen_anomalies\": state[\"seen_anomalies\"]\n",
        "    }\n"
      ],
      "metadata": {
        "id": "pC_AS400wVkt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "\n",
        "def deduplicate_event(state: AIOpsState) -> AIOpsState:\n",
        "    history = state[\"chat_history\"]\n",
        "    hash_id = hashlib.md5(state[\"anomalies\"].encode()).hexdigest()\n",
        "\n",
        "    if hash_id in state[\"seen_anomalies\"]:\n",
        "        history.append({\"role\": \"user\", \"content\": \"Duplicate anomaly detected. Skipping.\"})\n",
        "        history.append({\"role\": \"assistant\", \"content\": \"Anomaly already processed earlier.\"})\n",
        "    else:\n",
        "        state[\"seen_anomalies\"].add(hash_id)\n",
        "\n",
        "    return {\n",
        "        \"chat_history\": history,\n",
        "        \"anomalies\": state[\"anomalies\"],\n",
        "        \"seen_anomalies\": state[\"seen_anomalies\"]\n",
        "    }\n"
      ],
      "metadata": {
        "id": "sXej9mVWuF_3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.3, openai_api_key=openai.api_key)\n",
        "def aiops_agent(state: AIOpsState) -> AIOpsState:\n",
        "    history = state.get(\"chat_history\", [])\n",
        "\n",
        "    # Append new prompt with current anomaly\n",
        "    prompt = {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"Detected anomalies in system metrics:\\n\\n{state['anomalies']}\\n\n",
        "Explain the possible causes, impacts, and fixes.\"\"\"\n",
        "    }\n",
        "    history.append(prompt)\n",
        "\n",
        "    # Call ChatGPT\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=history\n",
        "    )\n",
        "    reply = response.choices[0].message.content.strip()\n",
        "\n",
        "    # Save model response\n",
        "    history.append({\"role\": \"assistant\", \"content\": reply})\n",
        "\n",
        "    return {\"chat_history\": history, \"anomalies\": state[\"anomalies\"]}\n"
      ],
      "metadata": {
        "id": "UfU_gE1Gpu1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16c15228-8fba-4422-b84b-b31a0cfcf08b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-13-1066192067.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model=\"gpt-4\", temperature=0.3, openai_api_key=openai.api_key)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "builder = StateGraph(state_schema=AIOpsState)\n",
        "builder.add_node(\"deduplicate_event\", deduplicate_event)\n",
        "builder.add_node(\"aiops_langchain_agent\", aiops_langchain_agent)\n",
        "\n",
        "builder.set_entry_point(\"deduplicate_event\")\n",
        "builder.add_edge(\"deduplicate_event\", \"aiops_langchain_agent\")\n",
        "builder.add_edge(\"aiops_langchain_agent\", END)\n",
        "\n",
        "graph = builder.compile()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Cl3DUD1E_8PD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "def generate_anomalies():\n",
        "    df = pd.DataFrame({\n",
        "        \"cpu\": np.random.normal(50, 10, 100),\n",
        "        \"memory\": np.random.normal(60, 15, 100),\n",
        "        \"disk_io\": np.random.normal(100, 25, 100),\n",
        "    })\n",
        "    df.iloc[95:100] += np.random.uniform(100, 200)\n",
        "    model = IsolationForest(contamination=0.05, random_state=42)\n",
        "    model.fit(df)\n",
        "    df[\"anomaly\"] = model.predict(df)\n",
        "    return df[df[\"anomaly\"] == -1].to_string(index=False)\n"
      ],
      "metadata": {
        "id": "oluO4jrRAAGB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Persistent memory state\n",
        "state = {\n",
        "    \"chat_history\": [],\n",
        "    \"seen_anomalies\": set()\n",
        "}\n",
        "\n",
        "# Simulate 2 anomaly events (same data to test deduplication)\n",
        "for i in range(2):\n",
        "    print(f\"\\n Run {i+1}\")\n",
        "    anomaly_str = generate_anomalies()\n",
        "    input_state = {\n",
        "        \"chat_history\": state[\"chat_history\"],\n",
        "        \"anomalies\": anomaly_str,\n",
        "        \"seen_anomalies\": state[\"seen_anomalies\"]\n",
        "    }\n",
        "    state = graph.invoke(input_state)\n",
        "\n",
        "    for msg in state[\"chat_history\"][-2:]:\n",
        "        print(f\"[{msg['role'].upper()}]: {msg['content']}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt_NiYpUwki2",
        "outputId": "d3bf2305-ab78-4ea9-ad2a-784acf845338"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Run 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-11-3375322124.py:10: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=prompt)\n",
            "/tmp/ipython-input-11-3375322124.py:12: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = chain.run(anomalies=state[\"anomalies\"])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[USER]: Detected anomalies in system metrics:\n",
            "\n",
            "       cpu     memory    disk_io  anomaly\n",
            "222.084508 217.853534 262.411635       -1\n",
            "231.252957 245.023815 269.386036       -1\n",
            "225.339937 227.214063 291.348540       -1\n",
            "226.897169 239.585032 285.333456       -1\n",
            "223.484506 248.074496 269.922889       -1\n",
            "Explain possible causes, system impact, and recommended actions.\n",
            "\n",
            "[ASSISTANT]: Possible Causes:\n",
            "1. High CPU usage: This could be due to a large number of processes running simultaneously, a single process consuming a large amount of CPU, or a CPU-intensive task such as data processing or video encoding.\n",
            "2. High Memory usage: This could be due to memory leaks in applications, too many applications running simultaneously, or large data sets being processed.\n",
            "3. High Disk IO: This could be due to large amounts of data being read from or written to the disk, such as during a backup operation, large file transfers, or heavy database operations.\n",
            "\n",
            "System Impact:\n",
            "1. High CPU usage can cause the system to slow down, become unresponsive, or even crash if the CPU becomes overheated.\n",
            "2. High Memory usage can also slow down the system, as the system may start swapping data to disk when it runs out of physical memory, which is much slower.\n",
            "3. High Disk IO can slow down data access and overall system performance, as other processes have to wait for disk access.\n",
            "\n",
            "Recommended Actions:\n",
            "1. High CPU usage: Identify the processes that are consuming the most CPU and determine if they are necessary. If not, consider terminating them. If they are necessary, consider optimizing them or upgrading the CPU.\n",
            "2. High Memory usage: Identify the processes that are consuming the most memory and determine if they are necessary. If not, consider terminating them. If they are necessary, consider optimizing them or adding more memory to the system.\n",
            "3. High Disk IO: Identify the processes that are causing the high disk IO and determine if they are necessary. If not, consider terminating them. If they are necessary, consider optimizing them or upgrading to a faster disk.\n",
            "\n",
            "\n",
            " Run 2\n",
            "[USER]: Detected anomalies in system metrics:\n",
            "\n",
            "       cpu     memory    disk_io  anomaly\n",
            "186.415741 179.146839 262.612216       -1\n",
            "196.075107 206.193554 240.071907       -1\n",
            "173.521075 182.676524 238.282461       -1\n",
            "193.955936 193.854082 211.350487       -1\n",
            "176.404852 200.583875 245.275149       -1\n",
            "Explain possible causes, system impact, and recommended actions.\n",
            "\n",
            "[ASSISTANT]: Possible Causes:\n",
            "1. High CPU Usage: This could be due to a large number of processes running simultaneously, or a single process consuming a significant amount of resources.\n",
            "2. High Memory Usage: This could be due to memory leaks in applications, or too many applications running at the same time.\n",
            "3. High Disk IO: This could be due to excessive reading/writing operations to the disk, which could be caused by large file transfers, or a high number of small, random reads and writes.\n",
            "\n",
            "System Impact:\n",
            "1. High CPU Usage: This can cause the system to slow down, and in extreme cases, it can cause the system to freeze or crash.\n",
            "2. High Memory Usage: This can cause the system to become slow and unresponsive. If the system runs out of memory, it may start using swap space on the hard drive, which is much slower than RAM.\n",
            "3. High Disk IO: This can slow down the system, as the disk is unable to keep up with the read/write requests. It can also cause wear and tear on the disk, shortening its lifespan.\n",
            "\n",
            "Recommended Actions:\n",
            "1. High CPU Usage: Identify the processes that are using the most CPU and determine if they are necessary. If they are not, consider terminating them. If they are necessary, consider optimizing them or upgrading your CPU.\n",
            "2. High Memory Usage: Identify the applications that are using the most memory and determine if they are necessary. If they are not, consider terminating them. If they are necessary, consider optimizing them or upgrading your RAM.\n",
            "3. High Disk IO: Identify the processes that are causing the high disk IO and determine if they are necessary. If they are not, consider terminating them. If they are necessary, consider optimizing them or upgrading your disk. Also, consider using a disk with a higher IO capacity.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}