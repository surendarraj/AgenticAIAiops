{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "qgNwkm0Ub7Ei"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain google-generativeai pandas numpy scikit-learn --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "yEwJGgPuzqPn"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain-openai --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "yu0Ir7ELl_G3"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-community --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "6zD9pE3YjlMj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain.prompts import PromptTemplate\n",
        "from huggingface_hub import login\n",
        "from typing import Any\n",
        "from dataclasses import dataclass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-FlUS84t-ho"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyD2t6GARAf_tgjN2ISqQhf4_EBInsRqxRM\"\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "siA2Iwj4zBKA"
      },
      "outputs": [],
      "source": [
        "from langchain_core.language_models.llms import LLM\n",
        "from pydantic import PrivateAttr\n",
        "from typing import ClassVar\n",
        "import google.generativeai as genai\n",
        "\n",
        "class GeminiLLM(LLM):\n",
        "    # Use a generally available model like gemini-1.5-flash-latest\n",
        "    model: ClassVar[str] = \"gemini-1.5-flash-latest\"\n",
        "    _client: genai.GenerativeModel = PrivateAttr()\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self._client = genai.GenerativeModel(self.model)\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"gemini\"\n",
        "\n",
        "    def _call(self, prompt: str, stop=None, run_manager=None, **kwargs) -> str:\n",
        "        response = self._client.generate_content(prompt)\n",
        "        return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "BpfyUklVSUmN"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate.from_template(\"\"\"\n",
        "You are an AIOps assistant.\n",
        "\n",
        "Below are system anomalies detected using Isolation Forest:\n",
        "\n",
        "{anomaly_text}\n",
        "\n",
        "Analyze the anomalies:\n",
        "- What are the likely root causes?\n",
        "- What is the system impact?\n",
        "- Recommend remediation steps.\n",
        "\"\"\")\n",
        "llm_chain = prompt | GeminiLLM()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "id": "TJCAQf6qSXm5",
        "outputId": "4b6cb77c-21ca-45c4-d382-6aa55c645b55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Calling Gemini for explanation...\n",
            "\n",
            "üß† Gemini Output:\n",
            "\n",
            "The provided data shows five anomalous data points detected by Isolation Forest, indicating deviations from the normal system behavior.  However, the data alone is insufficient to pinpoint precise root causes, system impact, or recommend specific remediation steps.  The anomaly score (-1) simply indicates an outlier; it doesn't provide details on the *type* of anomaly.  We need more context.\n",
            "\n",
            "**To effectively analyze these anomalies, we require the following information:**\n",
            "\n",
            "* **Baseline Data:**  We need a larger dataset representing normal system behavior.  Isolation Forest learns from normal data points; understanding the range and distribution of normal CPU, memory, and disk I/O usage is crucial.  The provided data only shows anomalies ‚Äì we lack the \"normal\" picture.\n",
            "* **System Details:**  What kind of system is this (server, application, cluster)? What operating system and applications are running? Knowing the system architecture is essential.\n",
            "* **Time Stamps:** The anomalies should have associated timestamps to understand if they occurred concurrently or sequentially.  This helps determine if they are related or independent events.\n",
            "* **Anomaly Severity:**  The \"-1\" is a generic anomaly score. A more informative score (e.g., a probability score or a distance measure from the normal data) would help prioritize the anomalies based on their severity.\n",
            "* **Other Metrics:**  Monitoring additional metrics like network traffic, process activity (CPU usage per process), and error logs would provide a more complete picture.\n",
            "\n",
            "\n",
            "**Possible Root Causes (Speculative, based on limited data):**\n",
            "\n",
            "Given the high values for CPU, memory, and disk I/O, potential root causes could include:\n",
            "\n",
            "* **Resource-intensive process:** A runaway process or a sudden surge in workload could consume significant CPU, memory, and disk resources.\n",
            "* **Software bug:** A bug in an application might lead to inefficient resource utilization.\n",
            "* **Hardware failure:**  While less likely to affect all three metrics simultaneously, a failing disk drive could cause high disk I/O, potentially cascading into CPU and memory issues due to system overhead.\n",
            "* **DoS attack:** A denial-of-service attack could overwhelm the system, resulting in high resource usage.\n",
            "\n",
            "\n",
            "**Potential System Impact (Speculative):**\n",
            "\n",
            "The impact depends on the severity and duration of the anomalies:\n",
            "\n",
            "* **Performance degradation:** Slow response times, application crashes, or system unresponsiveness.\n",
            "* **Service disruption:** Users might experience outages or reduced service quality.\n",
            "* **Data loss (potential):** In severe cases, if related to disk I/O issues, data corruption or loss is possible.\n",
            "\n",
            "\n",
            "**Recommended Remediation Steps (General, requires more data):**\n",
            "\n",
            "1. **Gather more data:** Collect detailed system logs, metrics, and traces to gain a comprehensive understanding of the anomalous events.\n",
            "2. **Investigate resource usage:** Analyze resource consumption per process to identify the culprit.  Tools like `top`, `htop` (Linux), or Resource Monitor (Windows) can be helpful.\n",
            "3. **Review application logs:** Check logs for error messages or warnings that might correlate with the anomalies.\n",
            "4. **Check system health:**  Monitor the hardware health (disks, memory, CPU) to rule out hardware problems.\n",
            "5. **Implement alerting:** Configure monitoring systems to generate alerts when anomalies occur, allowing for quicker response.\n",
            "6. **Capacity planning:** Assess the system's capacity to handle peak loads and plan for future growth.\n",
            "7. **Security audit (if suspected attack):** If a DoS attack is suspected, review security logs and implement appropriate security measures.\n",
            "\n",
            "\n",
            "In summary,  the provided data only scratches the surface.  A thorough investigation is needed, involving additional data collection and analysis, to diagnose the root causes, assess the impact, and implement effective remediation steps.\n",
            "\n",
            "\n",
            "üìä Evaluation Report:\n",
            "‚è±Ô∏è Latency: 7.44 seconds\n",
            "‚úÖ Keyword Coverage: 6/6\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Simulate synthetic system metrics\n",
        "def generate_anomalies():\n",
        "    df = pd.DataFrame({\n",
        "        'cpu': [random.gauss(50, 10) for _ in range(100)],\n",
        "        'memory': [random.gauss(60, 15) for _ in range(100)],\n",
        "        'disk_io': [random.gauss(100, 25) for _ in range(100)]\n",
        "    })\n",
        "    df.iloc[95:100] += random.uniform(100, 200)  # Inject anomalies\n",
        "    model = IsolationForest(contamination=0.05, random_state=42)\n",
        "    model.fit(df)\n",
        "    df[\"anomaly\"] = model.predict(df)\n",
        "    return df[df[\"anomaly\"] == -1]\n",
        "\n",
        "# Evaluate performance\n",
        "def evaluate_output(text: str, keywords: list[str]) -> int:\n",
        "    return sum(1 for kw in keywords if kw.lower() in text.lower())\n",
        "\n",
        "# Run the full pipeline\n",
        "anomalies_df = generate_anomalies()\n",
        "\n",
        "if anomalies_df.empty:\n",
        "    print(\"‚úÖ No anomalies detected.\")\n",
        "else:\n",
        "    anomaly_text = anomalies_df.to_string(index=False)\n",
        "\n",
        "    # Measure latency\n",
        "    print(\"üöÄ Calling Gemini for explanation...\\n\")\n",
        "    start = time.time()\n",
        "    result = llm_chain.invoke({\"anomaly_text\": anomaly_text})\n",
        "    duration = round(time.time() - start, 2)\n",
        "\n",
        "    # Print output\n",
        "    print(\"üß† Gemini Output:\\n\")\n",
        "    print(result)\n",
        "\n",
        "    # Keyword coverage evaluation\n",
        "    keywords = [\"cpu\", \"memory\", \"disk\", \"impact\", \"remediation\", \"cause\"]\n",
        "    score = evaluate_output(result, keywords)\n",
        "\n",
        "    print(\"\\nüìä Evaluation Report:\")\n",
        "    print(f\"‚è±Ô∏è Latency: {duration} seconds\")\n",
        "    print(f\"‚úÖ Keyword Coverage: {score}/{len(keywords)}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
