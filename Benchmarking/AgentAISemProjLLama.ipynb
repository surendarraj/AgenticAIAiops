{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "305rhqmosM3w"
      },
      "outputs": [],
      "source": [
        "#!pip install -U huggingface_hub scikit-learn pandas numpy --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN\n",
        "\n",
        "# Use LLaMA-3 or LLaMA-2 chat model\n",
        "client = InferenceClient(\n",
        "    model=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
        "    token=HUGGINGFACEHUB_API_TOKEN\n",
        ")\n"
      ],
      "metadata": {
        "id": "qs32cPCg3d-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "def generate_metrics():\n",
        "    df = pd.DataFrame({\n",
        "        \"cpu\": np.random.normal(50, 10, 100),\n",
        "        \"memory\": np.random.normal(60, 15, 100),\n",
        "        \"disk_io\": np.random.normal(100, 25, 100),\n",
        "    })\n",
        "    df.iloc[95:100] += np.random.uniform(100, 200)\n",
        "    return df\n",
        "\n",
        "def detect_anomalies(df):\n",
        "    model = IsolationForest(contamination=0.05, random_state=42)\n",
        "    model.fit(df)\n",
        "    df[\"anomaly\"] = model.predict(df)\n",
        "    return df[df[\"anomaly\"] == -1]\n"
      ],
      "metadata": {
        "id": "wgFm78tL3mT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_messages(anomalies_df):\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": \"You are an expert in AIOps.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"\"\"Detected anomalies (via Isolation Forest):\n",
        "\n",
        "{anomalies_df.to_string(index=False)}\n",
        "\n",
        "Please explain the root cause, possible impact, and recommended resolution.\"\"\"}\n",
        "    ]\n"
      ],
      "metadata": {
        "id": "9PpRCC_Q3qkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def evaluate_response(response_text, start_time):\n",
        "    duration = round(time.time() - start_time, 2)\n",
        "    words = len(response_text.split())\n",
        "\n",
        "    keywords = [\"cpu\", \"memory\", \"disk\", \"fix\", \"restart\", \"resource\", \"usage\"]\n",
        "    relevance_hits = sum(kw in response_text.lower() for kw in keywords)\n",
        "    relevance_score = round(relevance_hits / len(keywords), 2)\n",
        "\n",
        "    return {\n",
        "        \"latency_seconds\": duration,\n",
        "        \"word_count\": words,\n",
        "        \"relevance_score\": relevance_score,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "C8Th-cDd3tKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = generate_metrics()\n",
        "anomalies = detect_anomalies(df)\n",
        "\n",
        "if anomalies.empty:\n",
        "    print(\"âœ… No anomalies detected.\")\n",
        "else:\n",
        "    print(\"ðŸš¨ Anomalies detected. Sending to LLaMA...\\n\")\n",
        "    messages = build_messages(anomalies)\n",
        "\n",
        "    start = time.time()\n",
        "    response = client.chat_completion(messages=messages)\n",
        "    reply = response.choices[0].message.content.strip()\n",
        "\n",
        "    print(\"LLaMA Response:\\n\", reply)\n",
        "\n",
        "    metrics = evaluate_response(reply, start)\n",
        "    print(\"\\nðŸ“Š Evaluation Metrics:\")\n",
        "    for k, v in metrics.items():\n",
        "        print(f\" - {k}: {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xtRECvO3vt_",
        "outputId": "9c96d2ad-5bc6-4337-879c-381c9902a875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš¨ Anomalies detected. Sending to LLaMA...\n",
            "\n",
            "LLaMA Response:\n",
            " **Anomaly Detection Analysis**\n",
            "\n",
            "Based on the provided data, it appears that the anomalies were detected using the Isolation Forest algorithm, which is a robust and efficient method for outlier detection. The data points are characterized by CPU, memory, and disk I/O usage metrics.\n",
            "\n",
            "**Root Cause Analysis**\n",
            "\n",
            "After analyzing the data, it appears that the system is experiencing high disk I/O usage, which is likely the primary root cause of the anomalies. The disk I/O usage metrics are significantly higher than the CPU and memory usage metrics, suggesting that the system is experiencing resource bottlenecks related to disk operations.\n",
            "\n",
            "**Possible Impact**\n",
            "\n",
            "The high disk I/O usage can lead to several possible impacts on the system, including:\n",
            "\n",
            "1. **Performance degradation**: High disk I/O usage can lead to slower system response times, increased latency, and decreased overall performance.\n",
            "2. **Resource exhaustion**: If the system is unable to handle the high disk I/O demands, it may lead to resource exhaustion, causing the system to become unresponsive or even crash.\n",
            "3. **Data corruption or loss**: High disk I/O usage can increase the risk of data corruption or loss, particularly if the system is experiencing frequent disk seeks or write operations.\n",
            "\n",
            "**Recommended Resolution**\n",
            "\n",
            "To resolve the anomalies and mitigate the potential impacts, I recommend the following steps:\n",
            "\n",
            "1. **Disk performance optimization**: Perform disk performance optimization tasks, such as:\n",
            "\t* Defragmenting the disk to reduce fragmentation and improve disk access times.\n",
            "\t* Adjusting disk queue lengths to optimize disk I/O performance.\n",
            "\t* Configuring disk caching and buffering to reduce disk I/O demands.\n",
            "2. **Resource allocation adjustment**: Adjust resource allocation to ensure that the system has sufficient resources to handle the high disk I/O demands. This may involve:\n",
            "\t* Increasing disk storage capacity to reduce disk I/O demands.\n",
            "\t* Allocating more CPU and memory resources to the system to improve disk I/O performance.\n",
            "3. **Monitoring and alerting**: Implement monitoring and alerting mechanisms to detect and respond to high disk I/O usage in real-time. This will enable prompt identification and resolution of potential issues before they impact system performance.\n",
            "4. **Disk maintenance and replacement**: Regularly perform disk maintenance tasks, such as disk cleaning and disk replacement, to ensure optimal disk performance and prevent potential issues.\n",
            "\n",
            "By implementing these recommendations, you should be able to identify and resolve the root cause of the anomalies, mitigate potential impacts, and ensure optimal system performance.\n",
            "\n",
            "ðŸ“Š Evaluation Metrics:\n",
            " - latency_seconds: 7.1\n",
            " - word_count: 392\n",
            " - relevance_score: 0.71\n"
          ]
        }
      ]
    }
  ]
}