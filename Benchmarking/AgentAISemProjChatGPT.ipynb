{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8dMeesFY_s2b"
      },
      "outputs": [],
      "source": [
        "#!pip install openai scikit-learn pandas numpy --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "openai.api_key =userdata.get('OPEN_API_KEY')"
      ],
      "metadata": {
        "id": "3uDC681S_zmh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "def generate_metrics():\n",
        "    df = pd.DataFrame({\n",
        "        \"cpu\": np.random.normal(50, 10, 100),\n",
        "        \"memory\": np.random.normal(60, 15, 100),\n",
        "        \"disk_io\": np.random.normal(100, 25, 100),\n",
        "    })\n",
        "    df.iloc[95:100] += np.random.uniform(100, 200)\n",
        "    return df\n",
        "\n",
        "def detect_anomalies(df):\n",
        "    model = IsolationForest(contamination=0.05, random_state=42)\n",
        "    model.fit(df)\n",
        "    df[\"anomaly\"] = model.predict(df)\n",
        "    return df[df[\"anomaly\"] == -1]\n"
      ],
      "metadata": {
        "id": "_fgfcu5n_6SE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_messages(anomalies_df):\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": \"You are an expert in DevOps and anomaly detection.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"\"\"Detected anomalies in system metrics:\n",
        "\n",
        "{anomalies_df.to_string(index=False)}\n",
        "\n",
        "Please:\n",
        "1. Identify likely causes\n",
        "2. Describe potential system impact\n",
        "3. Suggest recommended actions\n",
        "\"\"\"}\n",
        "    ]\n"
      ],
      "metadata": {
        "id": "Cl3DUD1E_8PD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def evaluate_response(text, start_time):\n",
        "    duration = round(time.time() - start_time, 2)\n",
        "    words = len(text.split())\n",
        "    keywords = [\"cpu\", \"memory\", \"disk\", \"restart\", \"fix\", \"usage\", \"overload\"]\n",
        "    relevance_hits = sum(k in text.lower() for k in keywords)\n",
        "    relevance_score = round(relevance_hits / len(keywords), 2)\n",
        "    return {\n",
        "        \"latency_seconds\": duration,\n",
        "        \"word_count\": words,\n",
        "        \"relevance_score\": relevance_score\n",
        "    }\n"
      ],
      "metadata": {
        "id": "oluO4jrRAAGB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = generate_metrics()\n",
        "anomalies = detect_anomalies(df)\n",
        "\n",
        "if anomalies.empty:\n",
        "    print(\"âœ… No anomalies detected.\")\n",
        "else:\n",
        "    print(\"ðŸš¨ Anomalies found. Sending to GPT...\\n\")\n",
        "    messages = build_messages(anomalies)\n",
        "\n",
        "    start = time.time()\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",  # Change to gpt-4 or gpt-4o if you have access\n",
        "        messages=messages\n",
        "    )\n",
        "    reply = response.choices[0].message.content.strip()\n",
        "\n",
        "    print(\"ðŸ§  ChatGPT Response:\\n\")\n",
        "    print(reply)\n",
        "\n",
        "    metrics = evaluate_response(reply, start)\n",
        "    print(\"\\nðŸ“Š Evaluation Metrics:\")\n",
        "    for k, v in metrics.items():\n",
        "        print(f\" - {k}: {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne-kfXPoACU0",
        "outputId": "d3f27194-17cb-4b13-a7d8-577292c98530"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš¨ Anomalies found. Sending to GPT...\n",
            "\n",
            "ðŸ§  ChatGPT Response:\n",
            "\n",
            "Based on the provided system metrics and detected anomalies, here are some insights and recommendations:\n",
            "\n",
            "1. **Identified Anomalies**:\n",
            "    - Anomalies have been detected in the CPU, memory, and disk IO metrics.\n",
            "    - The anomalies are indicated by the value of -1 in the \"anomaly\" column.\n",
            "\n",
            "2. **Likely Causes**:\n",
            "    - Sudden spikes or drops in the metrics might be caused by processes consuming excessive resources.\n",
            "    - Incorrect resource allocation or inefficient usage by applications could lead to anomalies.\n",
            "    - Hardware failures or issues in the underlying infrastructure could also contribute to anomalies.\n",
            "\n",
            "3. **Potential System Impact**:\n",
            "    - High CPU usage can lead to performance degradation, slow response times, or even system crashes.\n",
            "    - Memory anomalies may result in memory leaks, leading to out-of-memory errors and system instability.\n",
            "    - Disk IO anomalies might slow down data read/write operations, impacting overall system performance.\n",
            "\n",
            "4. **Recommended Actions**:\n",
            "    - Monitor system metrics regularly to identify patterns and anomalies for proactive maintenance.\n",
            "    - Implement automated alerts or thresholds for abnormal metric values to promptly address issues.\n",
            "    - Conduct a thorough system performance analysis to identify any bottlenecks or resource hogs.\n",
            "    - Consider scaling resources or optimizing configurations to prevent future anomalies.\n",
            "    - Investigate the root cause of anomalies by analyzing system logs and application behavior.\n",
            "\n",
            "In summary, it is essential to promptly address anomalies in system metrics to ensure optimal performance, stability, and reliability of the system. Regular monitoring, proactive maintenance, and efficient resource management are key aspects of maintaining a healthy and high-performing system.\n",
            "\n",
            "ðŸ“Š Evaluation Metrics:\n",
            " - latency_seconds: 5.66\n",
            " - word_count: 249\n",
            " - relevance_score: 0.57\n"
          ]
        }
      ]
    }
  ]
}